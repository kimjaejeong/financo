# 2019-12-27



### Done

- 전원 클라우드 구축& skt bert 동작 확인 :clap::clap:

- 전처리에 관해서 토의(결론: `mecab`과 `sentence piece tokenizer`(이하 SPT)에 집중)
  - 고려 대상은 `khaiii`, `mecab`, `soynlp`, `SPT`였습니다.
  - khaiii는 형태소 분석은 잘 되지만 띄워쓰기 인식이 잘 안되고, 느린 추론 시간 때문에 배제 되었습니다.
  - soynlp는 아직 널리 사용되고 있지 않기 때문에(mecab과 SPT에 비해) 부족한 시간을 고려하여 mecab과 SPT에 집중하기로 했습니다.
  - mecab은 사용자 정의 사전 추가가 가능하기 때문에, 이를 이용하여 문자의 띄워쓰기가 올바르게 되도록 할 수 있습니다.(신조어에 취약하지만, 올바른 형태소 단위 인식이 잘 됩니다.)
  - SPT는 비지도학습이 가능하기 때문에 대상 `corpus`를 학습해서 OOV를 낮출 수 있습니다. (신조어도 잘 인식하나, 올바른 형태소 단위 인식은 잘 안되는 편입니다.)