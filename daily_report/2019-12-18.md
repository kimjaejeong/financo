# 2019-12-18



## To do List



### 완료 목록 - 요약

- Base Line 모델을 Bert로 하기로 구체화
- Bert 관련 정보 검색(T academy 자료 찾음 by 정우)
- 한국어 Bert 요청(ETRI)
- 일일 보고서 양식 작성 및 (17일 내용 소급 작성)

### 완료 목록 - 상세

- Base Line 모델을 Bert로 하기로 구체화
  - 현재 여러 대회들에서 SOTA(State Of The Art)를 차지한 XLnet을 Base Line으로 만들고 싶으나, 한글로 pretrained된 모델이 필요한데, XLnet은 그게 없을 확률이 높으니까 BERT를 Base Line 모델로 하기로 구체화 했음
- Bert 관련 정보 검색(T academy 자료 찾음 by 정우)
  - BERT 관련 자료가, 영화에 대한 감정분석인데 이 TASK가 이진 분류에 해당하기 때문에 중요한 자료라고 생각됩니다.
- 한국어 Bert 요청(ETRI)
  - SKT brain에서 한국어 BERT는 github에서 제공되고, ETRI는 요청을 해서 받아야 합니다. 요청 완료.



### 해야할 과제 목록

- Base Line 이후에 어떻게 차별점을 둘 지 생각



## 일일 과제

### Done

[재정]

- 분류문제는 빈도분석으로. Lstm, rnn 사용 x
- 데이터 나눠 학습하는 방법
  [https://m.blog.naver.com/PostView.nhn?blogId=abcd00pi&logNo=220850845493&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F](https://slack-redir.net/link?url=https%3A%2F%2Fm.blog.naver.com%2FPostView.nhn%3FblogId%3Dabcd00pi%26logNo%3D220850845493%26proxyReferer%3Dhttps%3A%2F%2Fwww.google.co.kr%2F)
  (보험사기적발 - 빅콘테스트 데이터 나누는 방법)
- 불균형 데이터 처리방법
  [https://sherry-data.tistory.com/m/13](https://slack-redir.net/link?url=https%3A%2F%2Fsherry-data.tistory.com%2Fm%2F13)
  (불균형 데이터 처리를 위하여)
- https://sherry-data.tistory.com/m/22?category=762078
  (불균형 데이터 셋 처리를 위한 training data 처리
- https://github.com/google-research/bert
  (Bert 소스코드)



[동욱]

- 전처리의 일반적인 과정: https://aileen93.tistory.com/m/128

- soynlp: https://github.com/lovit/soynlp/blob/master/README.md

  OOV(Out Of Vocab)를 해결하기 위한 라이브러리

  > 2016 년 10월의 연예기사 뉴스에는 '트와이스', '아이오아이' 와 같은 단어가 존재합니다. 하지만 말뭉치를 기반으로 학습된 품사 판별기 / 형태소 분석기는 이런 단어를 본 적이 없습니다. 늘 새로운 단어가 만들어지기 때문에 학습하지 못한 단어를 제대로 인식하지 못하는 미등록단어 문제 (out of vocabulry, OOV) 가 발생합니다. 하지만 이 시기에 작성된 여러 개의 연예 뉴스 기사를 읽다보면 '트와이스', '아이오아이' 같은 단어가 등장함을 알 수 있고, 사람은 이를 학습할 수 있습니다.

- 워드 피스 모델(WPM): https://lovit.github.io/nlp/2018/04/02/wpm/
  버트에서는 전처리를 위해서 WPM을 사용한다고 합니다. WPM에 관한 상세한 설명이 있는 자료입니다.



### Todo

- 정우가 찾은 T academy의 Bert 돌려보기. 가능하다면, 우리 자료로 해보기

