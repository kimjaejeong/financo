- 동욱이형 bert 수정 필요
  - build_data.py -> build_dataset.py

- 2019년 test 역시 vocab을 하고 학습을 해야 함.
- 해야할 것
  - 애매한 부분은 왜 애매한지 분석하는 것?
  - data를 보면서 빈도수를 보며 통계분석을 해야 할 듯.
- bert 설치 / 전처리 방향 / 주말 동안 할 것



내가 당장 해야할 것

- 5. 모델 실행 방법 업로드

- k80 - evaluate2.py 코드 주석 처리 해제하기.

  - 사진 참고

- v100 만들기

- mecab 어떤 방식으로 전처리 하는지 확인

- sentence piece, mecab 등 전처리 개념들 알아보기

  - sentence piece는 BPE 기반인데, mecab은 형태소이나, sentence piece는 문자(character) 하나를 쪼개서 BPE를 확인하는 것임. 따라서 사람들 것을 찾으면 좋음. 
  - mecab은 특정한 단어에 민감함.  미리 만들어도 데이터에 적용이 안될 가능성이 높음. 동작 방식이 다르기 때문에. 따라서 찾는 것이 의미가 없을 수 있음.

- 토요일 -> mecab 2번 / sentence piece 1번

  - 재정 - 오전 v100 만들고 dataset 확인
  - 경희 - 오전부터 mecab 데이터 셋 진행

- 일요일 -> mecab 1번 / sentence piece 2번

- git

  - 팀 fork -> 개인이 가지고 있고 

    팀 repisitory pull 받아서 개인에 local 가지고 있고 -> 개인 원격 push 날리고 -> pull request 날린 사람이 merge까지 하는 것으로.

    (배달의 민족 참고)



과제로 해야할 것

- v100으로 빨리 바꿔서 처음부터 진행

- 파일 찾기 - find
  안에 내용 확인 - grep 


  mecab 품사를 어떻게 알맞게 추가해야 할 지 / vocab 추가하는데 khaii와 mecab은 서로 다르다. 따라서 vocab 추가 방법 알아오기

  토요일 - 세개 정해서 기본적인거 제출 
  일요일 - 기본적인거 외에 전처리 해보고 세개 제출 / 빈도 분석 해서, 잘못 전처리 된 것을 수정해서 vocab을 하고, stopwords에서 삭제 과정을 진행.





차후에 해야할 것

- skeleteon 수정

- 파일 어떤식으로 업로드 할지?

- khaii, soynlp는 거의 안하는 방향으로?

  - 하지만, soynlp는 mecab과 섞일 수도 있음.
  - khaii는 속도가 매우느리다.
  - soynlp는 정보가 적어서, 탐색 시간이 많이 걸리듯.
    - sonlp로 전처리 해서 mecab에 집어넣는 것?
    - sonlp는 비지도 학습으로 신조어, 품사를 찾아낼 수 있음.

  